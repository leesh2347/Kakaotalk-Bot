#!/usr/bin/env python
# coding: utf-8
"""
MapleStory ì •ë³´ ê²€ìƒ‰ ë„ìš°ë¯¸ AI ì„œë²„
(RAG: ì§€ì¹¨ ì „ìš© / PDF ì œê±° / Gemini 2.5 Flash)
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‘œì¤€ ë° ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, pickle, faiss, uvicorn
import numpy as np
import json
import re
from typing import Optional
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
SERVER_HOST = os.getenv("SERVER_HOST", "0.0.0.0")
SERVER_PORT = int(os.getenv("SERVER_PORT", "8000"))
DEBUG_MODE  = os.getenv("DEBUG_MODE", "false").lower() == "true"
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
MAX_TOKENS = 2048
TEMPERATURE = 0.7

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FAISS ì¸ë±ìŠ¤ ë° ì„ë² ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INDEX_PATH = "data/faiss_index.idx"
META_PATH  = "data/faiss_index_meta.pkl"

EMBED_MODEL = SentenceTransformer("all-MiniLM-L6-v2")
embed = lambda t: EMBED_MODEL.encode(t, convert_to_numpy=True).astype("float32")

try:
    faiss_index = faiss.read_index(INDEX_PATH)
    faiss_meta  = pickle.load(open(META_PATH, "rb"))
    print(f"FAISS ë¡œë“œ ì™„ë£Œ: {faiss_index.ntotal} vectors")
except Exception as e:
    print("FAISS ë¡œë“œ ì‹¤íŒ¨:", e)
    faiss_index, faiss_meta = None, None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gemini ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
genai.configure(api_key="ì—¬ê¸°ì— ì œë¯¸ë‹ˆ api í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
model = genai.GenerativeModel(GEMINI_MODEL)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI ì•± ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="MapleStory Info Helper", version="1.0", debug=DEBUG_MODE)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pydantic ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AskReq(BaseModel):
    question: str

class AskRes(BaseModel):
    ì •ë³´: str
    ì˜µì…˜: str

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ /ask ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/ask", response_model=AskRes)
async def ask(req: AskReq):
    if faiss_index is None:
        raise HTTPException(500, "FAISS ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 1. ì§ˆë¬¸ â†’ ì§€ì¹¨ ì²­í¬ RAG
    qvec = np.array([embed(req.question)], dtype="float32")
    _, idx = faiss_index.search(np.array([embed(req.question)], dtype="float32"), 5)
    
    inst_chunks = []
    word_chunks = []
    
    for i in idx[0]:
        src = faiss_meta[i]["source"]
        chunk = faiss_meta[i]["chunk_text"]
        if src == "instruction":
            inst_chunks.append(chunk)
        elif src == "words":
            word_chunks.append(chunk)

     # â”€â”€ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚° ë° í”„ë¡¬í”„íŠ¸ì— ì‚½ì… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    today = datetime.datetime.now().strftime("%Y-%m-%d")  # YYYY-MM-DD í˜•ì‹


    # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = (
        "ë‹¤ìŒì€ AIê°€ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•  ì‘ë‹µ ì§€ì¹¨ì…ë‹ˆë‹¤:\n"
        + "\n".join(inst_chunks) + "\n\n"
        "ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¶•ì•½ì–´ ë° ì˜ë¯¸ì…ë‹ˆë‹¤:\n"
        + "\n".join(word_chunks) + "\n\n"
        f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today} ì…ë‹ˆë‹¤.\n\n"
        f"ì‚¬ìš©ì ì§ˆë¬¸: {req.question}\n"
        "ì§€ì¹¨ê³¼ ì¶•ì•½ì–´ ì •ë³´ë¥¼ ëª¨ë‘ ì°¸ê³ í•˜ì—¬, ë°˜ë“œì‹œ 'ì •ë³´'ì™€ 'ì˜µì…˜' ê°’ì„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    )

    try:
        response = model.generate_content(prompt)
        text = response.text.strip()

        # ğŸ‘‡ JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        match = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if not match:
            raise ValueError("ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        json_str = match.group(0)

        # ğŸ‘‡ ì•ˆì „í•œ JSON íŒŒì‹±
        parsed = json.loads(json_str)
        return AskRes(**parsed)

    except Exception as e:
        raise HTTPException(500, f"Gemini ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}\nì‘ë‹µ ë‚´ìš©:\n{text}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
async def health():
    return {"status": "ok", "model": GEMINI_MODEL}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„œë²„ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print(f"ë©”ì´í”Œ ë„ìš°ë¯¸ ì„œë²„ ì‹¤í–‰ â†’ http://{SERVER_HOST}:{SERVER_PORT}")
    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT, reload=DEBUG_MODE)
